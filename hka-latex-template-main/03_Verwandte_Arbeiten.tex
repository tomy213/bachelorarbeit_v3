\part{Verwandte Arbeiten}
\chapterimage{Bilder_und_Co/safety_sign_with_computer_code_and_a_airplane_in_the_background_1958542794.png} % Chapter heading image
%----------------------------------------------------------------------------------------
% --- optional: einheitliches Format für Annotationen ---
\newcommand{\ann}[3]{\textit{Kernaussage:} #1 \quad \textit{Relevanz:} #2 \quad \textit{Grenzen:} #3}

\chapter{Literatur Überblick}

\section{Normen und Behörden}
\begin{itemize}
  \item ISO/PAS 8800:2024 – Automotive-Rahmenwerk für AI Safety als Ergänzung zu ISO 26262/SOTIF.\\
  \ann{Definiert AI-Sicherheitslebenszyklus und Work-Products (Daten/Modell/V\&V/Betrieb).}
      {Prozess-Blaupause für KI-Assurance. Deckt die gleichen Bausteine bzw. Assurance Elemente ab, die im EASA AI Concept Paper gefordert werden.}
      {Automotive-Kontext; keine luftfahrtspezifischen DO-Norm Bezüge. Bezüge auf SOTIF Normen, die es so nicht in der Luftfahrt gibt.}

  \item ISO/IEC TR 5469:2024 – AI$\times$Funktionale Sicherheit.\\
  \ann{Ordnet KI im Kontext Funktionaler Sicherheit ein und führt Usage Levels (Nutzungsstufen) und AI-Technologieklassen ein, deren Kombination die Risikolage und die erforderliche Nachweistiefe für KI in sicherheitsrelevanten Funktionen strukturiert.}
      {Dient als Brücke zwischen Domänen,da sie nicht an eine gekoppelt ist. Und liefert genau die Argumentationsstruktur, die EASA für „Assurance-Evidenzen“ erwartet und ist somit ideal als Prozess-Rahmen neben DO-178C/ARP-Prozessen.
      Zudem ist sie konsistent mit der ISO 8800, da auf die Usage Level der ISO 5469 verwiesen werden.}
      {Sehr High-level; Keine Domänen Bezüge und kann daher nicht direkt angewandt werden.}

  \item ISO 21448 (SOTIF) – Safety of the Intended Functionality.\\
  \ann{Adressiert „insufficient performance“ und vorhersehbaren Fehlgebrauch via Szenarien/ODD.}
      {Adressiert Risikin obwohl kein Defekt vorliegt. Begründet die Wichtigkeit von ODD, OOD und mehr.}
      {Kein Bezug zur Luftfahrt; Ergänzt die ISO 26262.}

  \item ISO 26262 – Teil 1 (Begriffe) \& Teil 6 (Software-Entwicklung).\\
  \ann{Lieferte V-Modell, Unabhängigkeit der Verifikation, Toolkriterien und mehr (Die Automotive Version von der DO 178C).}
      {Funktionale Sicherheit des Automotive und Einordnung in Risikoklassifizierungen, so genannte ASIL Level (Das Äquivalent zu DAL Level).}
      {Nicht für Luftfahrt zugelassen, nur für Referenzrahmen.}

  \item ISO/IEC 22989 – AI: Begriffe und Konzepte.\\
  \ann{KI Terminologie vereinheitlicht.}
      {Sorgt für konsistente Begriffsverwendung in Anforderung/Reporting. Ebenfalls Branchen unabhängig.}
      {Nur für Definitionen.}

      
  \item DO-178C – Software Considerations in Airborne Systems \& Equipment.\\
  \ann{Nachweisweg für Luftfahrt-Software (DAL, Unabhängigkeit, DO-330 Tools).}
      {Definiert Ziele und Artefakte über den gesamten Software-Lebenszyklus. Anerkannt in der Luftfahrt}
      {Behandelt KI nicht explizit. Muss ergänzt werden durch DO 330.}

  \item DO-330 – Software Tool Qualification Considerations.\\
  \ann{Legt Qualifikationsziele und -artefakte für Entwicklungs-/Verifikationstools fest.}
      {Ermöglicht einen prüfbaren Nachweis für KI-Toolchain-Schritte (Data-Prep, Labeling, Training, Model-Konvertierung/Quantisierung), sofern deren Ergebnisse nicht vollständig anderweitig verifiziert werden können.}
      {Kein Algorithmusstandard; TQL wird pro Tool hergeleitet (nicht starr aus DAL).}

  \item EASA AI Concept Paper, Issue~2 (2024).\\
  \ann{Guidance für Level-1/2: ODD, Learning Assurance, Kalibrierung, Monitoring.}
      {Direkter Maßstab für „Assurance-Evidenzen“.}
      {Policy/Guidance, keine Algorithmen.}

  \item EASA AI Roadmap 2.0 (2023).\\
  \ann{Vision/Fahrplan für vertrauenswürdige KI, Lebenszyklus-Betrachtung.}
      {Rahmen, in den du dein Sicherheitsargument einordnest.}
      {Strategisch, nicht technisch.}


  \item EASA MLEAP Final Report (2024) – Machine Learning Application Approval.\\
  \ann{EASA-Forschungsbericht zu \emph{Learning Assurance} mit konkreten Nachweiswegen entlang Datenrepräsentativität, Generalisierung und Robustheit; validiert an Luftfahrt-Use-Cases.}
      {EASA-nahe Referenz für ODD-/Datenabdeckung, OOD/Generalisierung und robuste Metriken als Zulassungs-Evidenzen deiner Radar-Klassifikation.}
      {Guidance/Empfehlung, keine bindende Regel; Fokus auf Level-1/2-Anwendungen.}
\end{itemize}

\paragraph{Hinweis} Die oben genannten Quellen stützen v.\,a. Kapitel \S\ref{sec:grundlagen_radar_cls} (Rahmen) und die Sicherheitsabschnitte zu ODD/Kalibrierung.

\section{Luftfahrt-Zertifizierung und Forschung}
\begin{itemize}
  \item \textit{ML meets aerospace: challenges of certifying airborne AI} (Frontiers, 2024).\\
  \ann{Identifiziert Hürden: fehlende ODD-Disziplin, Kalibrierung, OOD/Abstain, Runtime.}
      {Beleg, warum Performance \emph{allein} nicht genügt.}
      {Übersicht; keine Radar-spezifischen Ergebnisse.}

  \item \textit{Towards certifiable AI in aviation} (2024).\\
  \ann{Landscape der Assurance-Bausteine (Traceability, Toolchain, Runtime).}
      {Checkliste für dein Evidenzpaket.}
      {Vorwiegend konzeptionell.}

  \item \textit{AI in Aviation Collegiate Education: Simple to Complex}.\\
  \ann{Curriculum/CBTA-Kontext.}
      {Optionaler Human-Factors-Beleg.}
      {Kein technischer Assurance-Nachweis.}
\end{itemize}

\section{Militärische Perspektive}
\begin{itemize}
  \item \textit{Standardization and certification on military AI applications} (JATM, 2024).\\
  \ann{Skizziert militärische Anforderungen und Lücken.}
      {Motiviert Defense-in-Depth als Kontext.}
      {Keine zivile Zulassung.}

  \item ECRS Mk1 (Eurofighter-Radar, HENSOLDT/Indra).\\
  \ann{Industriekontext \& Trend zu AI-gestützter Klassifikation.}
      {Einordnung, keine offenen Leistungsdaten.}
      {Öffentlich wenig technisch belastbar.}
\end{itemize}

\section{Radar-Objektklassifikation (Range-Doppler \& Mikro-Doppler)}
\begin{itemize}
  \item Chen, \textit{Micro-Doppler Effect in Radar}.\\
  \ann{Physik/Signaturen von Mikro-Doppler.}
      {Grundlage für featurehaltige RD/Spektrogramme.}
      {Buch, keine ML-Benchmarks.}

  \item Rahman et al. (2018), \textit{Sci. Reports}.\\
  \ann{Drone vs. Bird via Mikro-Doppler (Messdaten).}
      {Beleg für Trennschärfe der Signaturen.}
      {Kontrollierte Bedingungen.}

  \item Ritchie (2021).\\
  \ann{Überblick Verwechslungsfälle UAV/Bird.}
      {Hilft bei Fehleranalyse-Kategorien.}
      {Keine KI-Evaluierung.}

  \item Neuere DL-Ansätze (IET RSN; IEEE T-AES; \textit{Sensors}).\\
  \ann{CNN/3D-CNN/Sequenzmodelle auf RD/RAD.}
      {Methodenbasis für dein Modellkapitel.}
      {Selten ODD-stratifiziert/kalibriert.}
\end{itemize}

\section{OOD/Open-Set \& Unsicherheit/Kalibrierung}
\begin{itemize}
  \item Guo et al. (2017) – Calibration.\\
  \ann{Temperature Scaling; ECE/Brier/NLL.}
      {Pflichtbaustein für „ehrliche“ Konfidenzen.}
      {Post-hoc, keine OOD-Abdeckung.}

  \item Hendrycks \& Gimpel (2017) – MSP.\\
  \ann{Einfache OOD-Baseline.}
      {Baseline für deine OOD-Experimente.}
      {Begrenzt robust.}

  \item Liu et al. (2020) – Energy-based OOD.\\
  \ann{Stärkerer OOD-Score als MSP.}
      {Kandidat für dein OOD-Kriterium.}
      {Tuning nötig.}

  \item Geifman \& El-Yaniv (2019) – SelectiveNet.\\
  \ann{Risk-Coverage, Reject-Option.}
      {Direkter Link zu Abstain/Fallback.}
      {Training komplexer.}

  \item Lakshminarayanan et al. (2017) – Deep Ensembles.\\
  \ann{Epistemische Unsicherheit \& Robustheit.}
      {Kalibrierung/OOD verbessern.}
      {Mehr Rechenbudget.}

  \item Sensoy et al. (2018) – Evidential DL.\\
  \ann{Trennt Unsicherheitstypen im Output.}
      {Nützlich für Schwellen/Abstain.}
      {Reife abhängig von Domäne.}
\end{itemize}

% --- Synthese / Gap-Box ---
\subsection*{Synthese und Gap}
\noindent\textbf{Synthese:} Die Literatur belegt die Nützlichkeit von RD/\(\mu\)-Doppler und DL-Modellen; Regulatorik fordert jedoch ODD-stratifizierte, kalibrierte, OOD-fähige Nachweise mit Runtime-Belegen.\\
\textbf{Gap:} Fehlende ODD-Stratifizierung, wenige Kalibrierungsberichte, seltene Open-Set/Abstain-Evaluierung, kaum Realtime-Evidenzen.
